{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/trial.csv\",\n",
    "                sep=\",\", names=[\"word\",\"language\"],\n",
    "                skiprows=1)\n",
    "data= df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first_two( str ):\n",
    "    return str[:2]\n",
    "def last_two( str ):\n",
    "    return str[-2:]\n",
    "def first_three( str ):\n",
    "    return str[:3]\n",
    "def last_three( str ):\n",
    "    return str[-3:]\n",
    "    \n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "ngram_vectorizer = CountVectorizer(analyzer='char',encoding=\"latin-1\", ngram_range=(2, 3), preprocessor=None, min_df=1)\n",
    "first_two_vectorizer = CountVectorizer(analyzer='char',encoding=\"latin-1\", ngram_range=(2,2),preprocessor=first_two )\n",
    "last_two_vectorizer = CountVectorizer(analyzer='char', encoding=\"latin-1\",ngram_range=(2,2),preprocessor=last_two)\n",
    "first_three_vectorizer = CountVectorizer(analyzer='char', encoding=\"latin-1\",ngram_range=(2,2),preprocessor=first_three )\n",
    "last_three_vectorizer = CountVectorizer(analyzer='char',encoding=\"latin-1\", ngram_range=(2,2),preprocessor=last_three)\n",
    "\n",
    "combined_features = FeatureUnion([(\"ng\",ngram_vectorizer), (\"f2\",first_two_vectorizer),(\"l2\",last_two_vectorizer),(\"f3\",first_three_vectorizer),(\"l3\",last_three_vectorizer)])\n",
    "combined_features.fit(['di√°logo'])\n",
    "#print(ngram_vectorizer.get_feature_names())\n",
    "print(combined_features.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dword=df.word.tolist()\n",
    "dlang=df.language.tolist()\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    #'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    'clf__n_iter': (10, 50, 80),\n",
    "}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf = Pipeline([('features', combined_features),\n",
    "                     \n",
    "                     ('clf', SGDClassifier(loss='log'))\n",
    "])\n",
    "#grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "_ = txt_clf.fit(dword, dlang)\n",
    "                     \n",
    "#print(\"done in %0.3fs\" % (time() - t0))\n",
    "#print()\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = \"cachalote\"\n",
    "t = text_clf.predict_proba([val])\n",
    "test_val = t.max()\n",
    "print test_val\n",
    "result = text_clf.predict([val])\n",
    "ans = result.tolist()\n",
    "flag = ''.join(ans)\n",
    "print result\n",
    "#text_clf.predict(\"caboshed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from testing import *\n",
    "mat = getsearchtokens(\"performance management\")\n",
    "print mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
